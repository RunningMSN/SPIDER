import uuid
import os
import shutil
import subprocess
import math
from helpers.settings import blast_columns_fmt_6
import pandas as pd
import numpy as np


def setup(fasta, temp_directory):
    # Create temporary directory
    os.makedirs(temp_directory)

    # Copy assembly to the temp directory
    shutil.copy(fasta, f"{temp_directory}/reference.fasta")

    # Make blast DB for primer lookup
    makeblastdb_cmd = ["makeblastdb", "-in", f"{temp_directory}/reference.fasta", 
                       "-dbtype", "nucl"]
    subprocess.run(makeblastdb_cmd)

def cleanup(temp_directory):
    """
    Cleans up the temporary files generated by this script.
    """
    # Remove temporary directory
    shutil.rmtree(temp_directory)

def parse_primer_matches(vf_directory, expected_vf_length):
    # Parse the best forward primer match(es)
    try:
        # Read forward primer matches
        forward_matches = pd.read_csv(f"{vf_directory}/forward_primers.blast.txt", sep="\t", header=None, names=blast_columns_fmt_6)
        forward_matches["qseqid"] = forward_matches["qseqid"].str.replace("forward_", "")
        # Sort to make sure first primers are kept
        forward_matches["qseqid"] = forward_matches["qseqid"].astype(int)
        forward_matches.sort_values(by="qseqid", ascending = True, inplace= True)
        # Keep only matches for the best primer
        forward_matches = forward_matches[forward_matches["qseqid"] == forward_matches["qseqid"][0]]
        # Add information about strand
        forward_matches["strand"] = np.where(forward_matches["sstart"] < forward_matches["send"], "+", "-")
        print(forward_matches)
    # If no matches found, pandas will throw exception
    except pd.errors.EmptyDataError:
        forward_matches = None
    
    # Parse the best reverse primer match(es)
    try:
        # Read reverse primer matches
        reverse_matches = pd.read_csv(f"{vf_directory}/reverse_primers.blast.txt", sep="\t", header=None, names=blast_columns_fmt_6)
        reverse_matches["qseqid"] = reverse_matches["qseqid"].str.replace("reverse_", "")
        # Sort to make sure first primers are kept
        reverse_matches["qseqid"] = reverse_matches["qseqid"].astype(int)
        reverse_matches.sort_values(by="qseqid", ascending = True, inplace= True)
        # Keep only matches for the best primer
        reverse_matches = reverse_matches[reverse_matches["qseqid"] == reverse_matches["qseqid"][0]]
        # Add information about strand
        reverse_matches["strand"] = np.where(forward_matches["sstart"] < forward_matches["send"], "+", "-")
        print(reverse_matches)
    # If no matches found, pandas will throw exception
    except pd.errors.EmptyDataError:
        reverse_matches = None

    # Identify primer pairings where smallest number of primers in one set are paired with primers from other set
    # if forward_matches and reverse_matches:
    #     if len(forward_matches) <= len(reverse_matches):
    #         smaller, larger = forward_matches.copy(), reverse_matches.copy()
    #     else:
    #         smaller, larger = reverse_matches.copy(), forward_matches.copy()

    

def extract_vf(header, sequence, slide_limit, primer_size, temp_directory):
    """
    Identifies the virulence factor if present.
    """
    # Make directory for the VF
    vf_directory = f"{temp_directory}/{header.split(' ')[0].replace('>','')}"
    os.makedirs(vf_directory)

    # Find sequence length for number of primers to generate
    primer_slide_limit_nt = math.floor(slide_limit / 100 * len(sequence))

    # Number of primers to generate is primer size subtracted from the limit
    number_primers = primer_slide_limit_nt - primer_size

    # Generate the forward primers
    with open(f"{vf_directory}/forward_primers.fasta", "w") as forward_primers:
        for i in range(0, number_primers):
            forward_primers.write(f">forward_{i}\n{sequence[i:i+primer_size]}\n")

    # Generate the reverse primers
    with open(f"{vf_directory}/reverse_primers.fasta", "w") as reverse_primers:
        for i in range(0, number_primers):
            reverse_primers.write(f">reverse_{i}\n{sequence[len(sequence)-i-primer_size:len(sequence)-i]}\n")

    # BLAST both sets of primers
    for primer_set in ("forward_primers", "reverse_primers"):
        blast_cmd = ["blastn", "-query", f"{vf_directory}/{primer_set}.fasta", 
                     "-db", f"{temp_directory}/reference.fasta", 
                     "-outfmt", "6", "-word_size", "20", 
                     "-out", f"{vf_directory}/{primer_set}.blast.txt"]
        subprocess.run(blast_cmd)

    parse_primer_matches(vf_directory, len(sequence))

def crawl(fasta, db_loc, slide_limit, length, identity, primer_size):
    """
    Runs SPIDER to identify VFs in the supplied fasta file.
    """
    print(f"Beginning to crawl {fasta} using the following settings:")
    print(f"Primer Size: {primer_size}bp")
    print(f"Slide Limit: {slide_limit}%")
    print(f"Length: {length}%")
    print(f"Identity: {identity}%")

    # Create a temporary directory
    temp_directory = f"spider_tmp_{uuid.uuid4().hex}"

    # Setup crawler environment
    setup(fasta, temp_directory)

    # Iterate through all VFs to test
    with open(db_loc, "r") as database:
        # Load VFs by header and sequence
        for header, sequence in zip(database, database):
            extract_vf(header, sequence.strip(), slide_limit, primer_size, temp_directory)
            break # TEMPORARY BREAK TODO: REMOVE THIS

    # Cleanup temporary environment
    cleanup(temp_directory)